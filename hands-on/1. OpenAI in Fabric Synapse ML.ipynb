{"cells":[{"cell_type":"markdown","source":["## AI services in Fabric (preview)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9acb4409-eb91-47a2-972e-fe34e1b80ba1"},{"cell_type":"markdown","source":["### Utilizing Azure AI Services in Fabric\n","\n","Fabric offers two distinct options for leveraging Azure AI services:\n","\n","#### 1. Pre-built AI Models in Fabric (Preview)\n","\n","Fabric integrates seamlessly with Azure AI services, enabling you to enhance your data with pre-built AI models without any prerequisites. This is the recommended approach, as you can use your Fabric authentication to access these AI services, with all usage billed against your Fabric capacity. Currently, this option is in public preview, with a limited selection of AI services available.\n","\n","Available AI services include:\n","- **Azure OpenAI Service** (Rest API, Python SDK, Synapse ML)\n","- **Text Analytics** (Rest API, Synapse ML)\n","- **Azure AI Translator** (Rest API, Synapse ML)\n","\n","These services are accessible out of the box in Fabric, supporting both RESTful API and SynapseML. You can also use the OpenAI Python Library to access the Azure OpenAI service within Fabric. For more details on the available models, refer to [prebuilt AI models in Fabric](#).\n","\n","#### 2. Bring Your Own Key (BYOK)\n","\n","If you prefer to provision your AI services directly on Azure, you can bring your own key (BYOK) to access them from Fabric. This option is ideal if the AI services you need aren't yet supported by the pre-built AI models in Fabric.\n","\n","For more information on using Azure AI services with BYOK, visit [Azure AI services in SynapseML with bring your own key](#).\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dc3b154d-69ed-490e-9f8f-f16b587a1e3f"},{"cell_type":"markdown","source":["**Note:**  \n","-  Prebuilt AI models are currently available in preview and are offered for free with certain limitations. Specifically, for OpenAI models, the limit is 20 requests per minute per user.\n","-  Support gpt-35-turbo, gpt-4-32K, text-embedding-ada-002 (version 2)\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"73bb6019-9af9-43dc-81c0-51fba3a20315"},{"cell_type":"code","source":["import synapse.ml.core\n","from synapse.ml.services.openai import *"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d8809346-f514-4c91-8ad3-c248af662639"},{"cell_type":"markdown","source":["## Chat \n","\n","ChatGPT and GPT-4 models are language models that are optimized for conversational interfaces."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"668babcf-c9ff-4b36-a245-48efd13f088e"},{"cell_type":"code","source":["from synapse.ml.services.openai import OpenAIChatCompletion\n","from pyspark.sql import Row\n","from pyspark.sql.types import *\n","\n","\n","def make_message(role, content):\n","    return Row(role=role, content=content, name=role)\n","\n","\n","chat_df = spark.createDataFrame(\n","    [\n","        (\n","            [\n","                make_message(\n","                    \"system\", \"You are an AI chatbot with red as your favorite color\"\n","                ),\n","                make_message(\"user\", \"Whats your favorite color\"),\n","            ],\n","        ),\n","        (\n","            [\n","                make_message(\"system\", \"You are very excited\"),\n","                make_message(\"user\", \"How are you today\"),\n","            ],\n","        ),\n","    ]\n",").toDF(\"messages\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"d91e7c77-8230-49f0-a359-c819eaab2884"},{"cell_type":"code","source":["\n","\n","chat_completion = (\n","    OpenAIChatCompletion()\n","    .setDeploymentName(\"gpt-35-turbo-0125\") # deploymentName could be one of {gpt-35-turbo-0125 or gpt-4-32k}\n","    .setMessagesCol(\"messages\")\n","    .setErrorCol(\"error\")\n","    .setOutputCol(\"chat_completions\")\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7b055847-956d-41e9-b575-de2611e1d6ff"},{"cell_type":"code","source":["chat_completion_df = chat_completion.transform(chat_df).select(\n","        \"messages\", \"chat_completions.choices.message.content\"\n","    )"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d6844749-39c2-4049-a394-7f4ffdedca8d"},{"cell_type":"code","source":["display(chat_completion_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"70b10fa3-3102-4e96-910d-4eccceca6d54"},{"cell_type":"markdown","source":["Output should look something like below\n","\n","| messages                                                                                                                                                                 | content                                                                                   |\n","|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------|\n","| [{role='system', content='You are an AI chatbot with red as your favorite color', name='system'), Row(role='user', content='Whats your favorite color', name='user'}] | ['My favorite color is red! What about you?']                                             |\n","| [{role='system', content='You are very excited', name='system'), Row(role='user', content='How are you today', name='user'}]                                          | [\"I'm doing great, thank you for asking! I'm feeling really excited today. How are you?\"] |"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"134dfd5b-ee66-4d06-8736-ec6be349d7a4"},{"cell_type":"markdown","source":["# Embeddings"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5a5a75d3-0256-4be3-bd79-5a4d056a73fa"},{"cell_type":"code","source":["from pyspark.sql import Row\n","\n","data = [\n","    Row(text='The early bird catches the worm.'),\n","    Row(text='Knowledge is power.'),\n","    Row(text='Actions speak louder than words.'),\n","    Row(text='A picture is worth a thousand words.')\n","]\n","\n","# Create DataFrame\n","df = spark.createDataFrame(data)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3b344ca9-9403-4f30-afe7-0b87ee386538"},{"cell_type":"code","source":["embedding = (\n","    OpenAIEmbedding()\n","    .setDeploymentName(\"text-embedding-ada-002\") # set deployment_name as text-embedding-ada-002\n","    .setTextCol(\"text\")\n","    .setOutputCol(\"out\")\n",")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"15b33c57-2035-4749-9332-3959142f4140"},{"cell_type":"code","source":["embedding_df = embedding.transform(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e03fde52-e0b4-4b61-be92-7b5b96946b87"},{"cell_type":"code","source":["display(embedding_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"cf22c763-75f4-4a70-b9b8-7f702078098f"},{"cell_type":"markdown","source":["Your output should look something like this. Number of values in array may be different\n","\n","| text                                                      | OpenAIEmbedding_cb1548908c98_error | out                                                                                                                                                                                        |\n","|:----------------------------------------------------------|:-----------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| The early bird catches the worm.                          |                                   | {\"type\":1,\"values\":[0.004523789,-0.019567443,0.018745321,-0.015432109,-0.013654789,0.004321876,-0.016543210,-0.012345678,-0.006543210,-0.024567890,0.017123456,0.035678901,0.013456789,-0.002345678,-0.001234567,-0.010987654,0.028765432,-0.018765432,0.026543210]} |\n","| Knowledge is power.                                       |                                   | {\"type\":1,\"values\":[0.003654321,-0.021234567,0.016789012,-0.013456789,-0.015432109,0.002345678,-0.014321098,-0.010987654,-0.007654321,-0.026543210,0.015678901,0.033456789,0.011234567,-0.002987654,-0.003456789,-0.009876543,0.027654321,-0.016789012,0.024567890]} |\n","| Actions speak louder than words.                          |                                   | {\"type\":1,\"values\":[0.005678901,-0.020987654,0.017654321,-0.014567890,-0.013456789,0.005432109,-0.017890123,-0.011234567,-0.008765432,-0.023456789,0.018901234,0.034567890,0.013456789,-0.001234567,-0.002345678,-0.011098765,0.028901234,-0.017123456,0.026789012]} |\n","| A picture is worth a thousand words.                      |                                   | {\"type\":1,\"values\":[0.003987654,-0.019876543,0.018012345,-0.014987654,-0.014321098,0.003456789,-0.015678901,-0.012345678,-0.005678901,-0.025678901,0.017890123,0.032345678,0.012345678,-0.001987654,-0.002345678,-0.010123456,0.029876543,-0.016543210,0.024987654]} |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"82858395-e37c-4485-9ea3-0043322b4480"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{}},"nbformat":4,"nbformat_minor":5}