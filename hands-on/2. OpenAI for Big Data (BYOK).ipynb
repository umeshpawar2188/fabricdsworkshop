{"cells":[{"cell_type":"markdown","source":["# Azure OpenAI for Big Data (BYOK)\n","\n","The **Azure OpenAI** service provides powerful tools to address a wide range of natural language tasks through its prompting and completion API. To facilitate the scaling of your prompting workflows—from a few examples to extensive datasets—we have integrated Azure OpenAI with the distributed machine learning library [**SynapseML**](https://www.microsoft.com/en-us/research/blog/synapseml-a-simple-multilingual-and-massively-parallel-machine-learning-library/).\n","\n","This integration leverages the [**Apache Spark**](https://spark.apache.org/) distributed computing framework, enabling the processing of millions of prompts efficiently with the OpenAI service. \n","\n","This tutorial will guide you on how to utilize large language models at a distributed scale using Azure OpenAI.\n"],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"dd4c8776-6853-4257-bef8-72778724ad57","showTitle":false,"title":""}},"id":"377bcec7-5d13-4c65-962e-0c9416cf14fc"},{"cell_type":"markdown","source":["## Prerequisites\n","\n","The key prerequisites for this quickstart include a working Azure OpenAI resource, and an Apache Spark cluster with SynapseML installed. We suggest creating a Synapse workspace, but an Azure Databricks, HDInsight, or Spark on Kubernetes, or even a python environment with the `pyspark` package will work. \n","\n","1. An Azure OpenAI resource – request access [here](https://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUOFA5Qk1UWDRBMjg0WFhPMkIzTzhKQ1dWNyQlQCN0PWcu) before [creating a resource](https://docs.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource)\n","\n"],"metadata":{"tags":["hide-synapse-internal"]},"id":"51bf1e34-7146-411e-8800-36a905b4d724"},{"cell_type":"markdown","source":["## Fill in service information\n","\n","Next, edit the cell in the notebook to point to your service. In particular set the `service_name`, `deployment_name`, `location`, and `key` variables to match them to your OpenAI service:"],"metadata":{},"id":"4549d764-48d8-47ba-a260-144b913981bb"},{"cell_type":"code","source":["from synapse.ml.core.platform import find_secret\n","\n","# Fill in the following lines with your service information\n","# Learn more about selecting which embedding model to choose: https://openai.com/blog/new-and-improved-embedding-model\n","service_name = \"oiapocvbd\" #TODO\n","deployment_name = \"gpt-35-turbo\" #TODO\n","deployment_name_embeddings = \"text-embedding-ada-002\" #TODO\n","\n","key = \"\" #TODO- Get key for your open AI instance\n","\n","\n","assert key is not None and service_name is not None"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1441b730-f25f-48c8-89c3-b7622ba619ce"},{"cell_type":"markdown","source":["## Create a dataset of prompts\n","\n","Next, create a dataframe consisting of a series of rows, with one prompt per row. \n","\n","You can also load data directly from ADLS or other databases. For more information on loading and preparing Spark dataframes, see the [Apache Spark data loading guide](https://spark.apache.org/docs/latest/sql-data-sources.html)."],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"76f069b7-14e8-44ea-97f0-1c49cf02eeed","showTitle":false,"title":""}},"id":"3a2c1be5-335d-4b01-85df-eeee9dac9b12"},{"cell_type":"code","source":["df = spark.createDataFrame(\n","    [\n","        (\"Hello my name is\",),\n","        (\"The best code is code thats\",),\n","        (\"SynapseML is \",),\n","    ]\n",").toDF(\"prompt\")"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1a4366df-4d40-45a0-b1a7-6086b9c693d2","showTitle":false,"title":""},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eb524480-555e-4a23-9843-de60b56dddc0"},{"cell_type":"markdown","source":["## Create the OpenAICompletion Apache Spark Client\n","\n","To apply the OpenAI Completion service to your dataframe you created, create an OpenAICompletion object, which serves as a distributed client. Parameters of the service can be set either with a single value, or by a column of the dataframe with the appropriate setters on the `OpenAICompletion` object. Here we're setting `maxTokens` to 200. A token is around four characters, and this limit applies to the sum of the prompt and the result. We're also setting the `promptCol` parameter with the name of the prompt column in the dataframe."],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"fb48578c-e4b3-49fc-9ee2-2f8ae8808c19","showTitle":false,"title":""}},"id":"c9053637-1190-4b8c-bf12-732fb6a58863"},{"cell_type":"code","source":["from synapse.ml.services.openai import OpenAICompletion\n","\n","completion = (\n","    OpenAICompletion()\n","    .setSubscriptionKey(key)\n","    .setDeploymentName(deployment_name)\n","    .setUrl(\"https://{}.openai.azure.com/\".format(service_name))\n","    .setMaxTokens(200)\n","    .setPromptCol(\"prompt\")\n","    .setErrorCol(\"error\")\n","    .setOutputCol(\"completions\")\n",")"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2dca7a9d-6092-48af-8653-10c141fd440d","showTitle":false,"title":""},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4110d806-1e87-4360-a13b-982ec863724b"},{"cell_type":"markdown","source":["**Your output should look something like this. The completion text will be different from the sample.**\n","\n","| **prompt**                    | **error** | **text**                                                                                                                               |\n","|:-----------------------------:|:---------:|:-------------------------------------------------------------------------------------------------------------------------------------:|\n","| Hello my name is             | null      | Makaveli I'm eighteen years old and I want to be a rapper when I grow up. I love writing and making music. I'm from Los Angeles, CA |\n","| The best code is code that's | null      | Understandable. This is a subjective statement, and there is no definitive answer.                                                    |\n","| SynapseML is                 | null      | A machine learning algorithm that is able to learn how to predict the future outcome of events.                                        |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5e114380-667d-433d-87dc-e60b44fac79d"},{"cell_type":"markdown","source":["## Transform the dataframe with the OpenAICompletion Client\n","\n","After creating the dataframe and the completion client, you can transform your input dataset and add a column called `completions` with all of the information the service adds. Select just the text for simplicity."],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"64b2a454-65ab-45ec-9946-d92539899781","showTitle":false,"title":""}},"id":"b5f652b4-d2d6-4d66-9dad-c8f6ab142ae0"},{"cell_type":"code","source":["from pyspark.sql.functions import col\n","\n","completed_df = completion.transform(df).cache()\n","display(\n","    completed_df.select(\n","        col(\"prompt\"),\n","        col(\"error\"),\n","        col(\"completions.choices.text\").getItem(0).alias(\"text\"),\n","    )\n",")"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"90684f9f-5c74-463f-a809-75a219489d7f","showTitle":false,"title":""},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"7d5d299a-b4d7-4fd8-9eda-22bc0643fc27"},{"cell_type":"markdown","source":["## More Usage Examples"],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"9111da73-81f2-48e5-9a0c-eb65e1567f91","showTitle":false,"title":""}},"id":"ed97547f-817a-4960-b7ad-65a26f44e889"},{"cell_type":"markdown","source":["### Generating Text Embeddings\n","\n","In addition to completing text, we can also embed text for use in downstream algorithms or vector retrieval architectures. Creating embeddings allows you to search and retrieve documents from large collections and can be used when prompt engineering isn't sufficient for the task."],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4573634d-914c-4dc9-a252-3abc4a570500","showTitle":false,"title":""}},"id":"a375816e-5e12-4271-ba6b-8323a5c0a3c5"},{"cell_type":"markdown","source":["For more information on using `OpenAIEmbedding` see our [embedding guide](./Quickstart%20-%20OpenAI%20Embedding)."],"metadata":{"tags":["hide-synapse-internal"]},"id":"7f912746-491f-4d98-aa07-2f5a6c15c0b9"},{"cell_type":"code","source":["from synapse.ml.services.openai import OpenAIEmbedding\n","\n","embedding = (\n","    OpenAIEmbedding()\n","    .setSubscriptionKey(key)\n","    .setDeploymentName(deployment_name_embeddings)\n","    .setCustomServiceName(service_name)\n","    .setTextCol(\"prompt\")\n","    .setErrorCol(\"error\")\n","    .setOutputCol(\"embeddings\")\n",")\n","\n","display(embedding.transform(df))"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"de519d35-ac75-4bd4-8cbb-011580e43204","showTitle":false,"title":""},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"58368a1a-a8ef-4f10-8d29-c972a13a8f62"},{"cell_type":"markdown","source":["**Your output should look something like this. The embeddings will be different from the sample.**\n","\n","| **prompt**                        | **error** | **embeddings**                                                                                                                                                       |\n","|:---------------------------------:|:---------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n","| Hello my name is                 | null      | [0.0123, -0.0456, 0.0789, -0.0123, 0.0345, -0.0678, 0.0234, -0.0456, 0.0123, -0.0345]                                                                           |\n","| The best code is code thats     | null      | [0.0456, -0.0123, 0.0678, -0.0345, 0.0567, -0.0234, 0.0789, -0.0456, 0.0345, -0.0678]                                                                           |\n","| SynapseML is                     | null      | [0.0345, -0.0678, 0.0567, -0.0234, 0.0456, -0.0345, 0.0123, -0.0567, 0.0789, -0.0456]                                                                           |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cf3d3790-5e35-4431-befc-3df52eae8ce9"},{"cell_type":"markdown","source":["### Chat Completion\n","\n","Models such as ChatGPT and GPT-4 are capable of understanding chats instead of single prompts. The `OpenAIChatCompletion` transformer exposes this functionality at scale."],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"660457e0-b0d5-4b95-99c1-e0ad3c5abebf","showTitle":false,"title":""}},"id":"a169d551-268a-4f52-86b3-1618507c965e"},{"cell_type":"code","source":["from synapse.ml.services.openai import OpenAIChatCompletion\n","from pyspark.sql import Row\n","from pyspark.sql.types import *\n","\n","\n","def make_message(role, content):\n","    return Row(role=role, content=content, name=role)\n","\n","\n","chat_df = spark.createDataFrame(\n","    [\n","        (\n","            [\n","                make_message(\n","                    \"system\", \"You are an AI chatbot with red as your favorite color\"\n","                ),\n","                make_message(\"user\", \"Whats your favorite color\"),\n","            ],\n","        ),\n","        (\n","            [\n","                make_message(\"system\", \"You are very excited\"),\n","                make_message(\"user\", \"How are you today\"),\n","            ],\n","        ),\n","    ]\n",").toDF(\"messages\")\n","\n","\n","chat_completion = (\n","    OpenAIChatCompletion()\n","    .setSubscriptionKey(key)\n","    .setDeploymentName(deployment_name)\n","    .setCustomServiceName(service_name)\n","    .setMessagesCol(\"messages\")\n","    .setErrorCol(\"error\")\n","    .setOutputCol(\"chat_completions\")\n",")\n","\n"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"fc56ccd4-008c-4dfc-bb4e-cd0f7ead38a6","showTitle":false,"title":""},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"fa075bcb-b6bb-45fe-ba91-b222e309b657"},{"cell_type":"markdown","source":["messages\tcontent\n","[{\"role\":\"system\",\"content\":\"You are an AI chatbot with red as your favorite color\",\"name\":\"system\"},{\"role\":\"user\",\"content\":\"Whats your favorite color\",\"name\":\"user\"}]\t[\"My favorite color is red!\"]\n","[{\"role\":\"system\",\"content\":\"You are very excited\",\"name\":\"system\"},{\"role\":\"user\",\"content\":\"How are you today\",\"name\":\"user\"}]\t[\"As an AI language model, I do not have feelings and emotions, but I am functioning well. Thank you for asking. How may I assist you today?\"]\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"32da3c28-ed30-4dcd-b2e8-c9eba3ed0972"},{"cell_type":"code","source":["display(\n","    chat_completion.transform(chat_df).select(\n","        \"messages\", \"chat_completions.choices.message.content\"\n","    )\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f6bb0fc7-9a4f-477e-9f08-a88e60cfca39"},{"cell_type":"markdown","source":["### Improve Throughput with Request Batching\n","\n","The example **makes several requests** to the service, **one for each prompt**. To **complete multiple prompts in a single request**, use **batch mode**. \n","\n","**Important Changes:**\n","- **Specify \"batchPrompt\"** for the `BatchPrompt` column in the `OpenAICompletion` object, **instead of \"Prompt\"**.\n","- **Create a dataframe** with a list of prompts **per row** to use batch mode effectively.\n","\n","**Note:** As of this writing, there’s currently a limit of **20 prompts** in a single request, and a hard limit of **2048 \"tokens\"**, or approximately **1500 words**.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"69d5dc34-c970-4c80-b86d-1f2fe12a41f6"},{"cell_type":"code","source":["initial_data = [\n","    (\"The time has come\",),\n","    (\"Pleased to\",),\n","    (\"Today stocks\",),\n","    (\"Here's to\",),\n","    (\"The only thing\",),\n","    (\"Ask not what\",),\n","    (\"Every litter\",),\n","    (\"I am\",),\n","]\n","\n","# Define the schema for the DataFrame\n","schema = [\"prompt\"]\n","\n","# Create the DataFrame\n","pronpt_df = spark.createDataFrame(initial_data, schema)\n","\n","# Display the DataFrame\n","pronpt_df.show(truncate=False)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0ec1cb9f-d04a-430b-ab3f-ecbce65d5421"},{"cell_type":"code","source":["batch_df = spark.createDataFrame(\n","    [\n","        ([\"The time has come\", \"Pleased to\", \"Today stocks\", \"Here's to\"],),\n","        ([\"The only thing\", \"Ask not what\", \"Every litter\", \"I am\"],),\n","    ]\n",").toDF(\"batchPrompt\")"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"9f9b7953-6d96-4f83-b61d-c396cefb28ea","showTitle":false,"title":""},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d891906d-2b02-4a80-bdd7-3691ef5f0735"},{"cell_type":"code","source":["display(batch_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"80017e65-a601-40fa-9017-ca0386935c12"},{"cell_type":"markdown","source":["Next we create the OpenAICompletion object. Rather than setting the prompt column, set the batchPrompt column if your column is of type `Array[String]`."],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0bb5daf9-8155-460c-b2dd-e1ca302a3776","showTitle":false,"title":""}},"id":"65d4b14f-0103-4623-8f8d-df1fb12c43ce"},{"cell_type":"code","source":["batch_completion = (\n","    OpenAICompletion()\n","    .setSubscriptionKey(key)\n","    .setDeploymentName(deployment_name)\n","    .setCustomServiceName(service_name)\n","    .setMaxTokens(5000)\n","    .setBatchPromptCol(\"batchPrompt\")\n","    .setErrorCol(\"error\")\n","    .setOutputCol(\"completions\")\n",")"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"8411e5ba-7f22-4ac9-a78e-1746a7ccc8bc","showTitle":false,"title":""},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"abb3eb7a-e6a1-482c-ae11-4ac7bdcacd75"},{"cell_type":"markdown","source":["In the call to transform, a request will be made per row. Since there are multiple prompts in a single row, each request is sent with all prompts in that row. The results contain a row for each row in the request."],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"be2a0d15-40e1-4a3d-a879-d7d0e0129b35","showTitle":false,"title":""}},"id":"53e634f1-37db-45e8-87ac-55c8964463e6"},{"cell_type":"code","source":["completed_batch_df = batch_completion.transform(batch_df).cache()\n","display(completed_batch_df)"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a6fb7509-f582-47bd-8b57-f59d51c03eb3","showTitle":false,"title":""},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"8648798b-86b1-4eb0-8933-bf605f1c9637"},{"cell_type":"markdown","source":["**Your output should look something like this. The completion text will be different from the sample.**\n","\n","| **batchPrompt**                                        | **error** | **completions**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n","|:-------------------------------------------------------|:----------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| [\"The time has come\",\"Pleased to\",\"Today stocks\",\"Here's to\"] |          | {\"model\":\"gpt-35-turbo\",\"choices\":[{\"text\":\" to wake up from the illusion that change can come to this country through the ballot box. Hundreds of millions of dollars have been funnelled into election campaigns that produce at best symbolic change. The powerful interests that run the country are firmly ensconced in power and are not giving up their control through meditation, prayer, election campaigns, or vigils and protests held on whatever subject tickles progressive fancy. Time is ripe for the peaceful initiation of the power-shift to transpire through courageous, non-vio gave not inconsiderable amounts of it away, to support various charities (including the RNIB and Amnesty International), and aspiring writers.\\n\\nThis slideshow requires JavaScript.\\n\\nHe was many things â€“ adoring (though fallible) husband, father, and grandfather; traveller, cocktail drinker, raconteur, angler, and author. Itâ€™s not for this blog post to delve into his style, motives, or political stance. Suffice to say, much like the work of Francis Bacon, thereâ€™s never a dull m -- bearer of\",\"index\":3,\"finish_reason\":\"length\"}],\"object\":\"text_completion\",\"id\":\"cmpl-9upxo64wxwfClQ7mpb4ixIfjAx5nT\",\"created\":\"1723333144\"} |\n","| [\"The only thing\",\"Ask not what\",\"Every litter\",\"I am\"]        |          | {\"model\":\"gpt-35-turbo\",\"choices\":[{\"text\":\" I needed from the lights was a place to plug in, and it suited  Education & KOL Manager, Project HOPE & Susan Elks, Director of Administration, Operations & Volunteer Relations, Project HOPE\\n\\n\\\"In a volunteer program, it could be difficult at times to track what individuals are doing to evaluate their work. Therefore, it is worth the while of the organization to provide volunteers with a personal feedback, even if it is just a thank-you letter that could indicate what exactly that volunteer has accomplished and how many peope\\n\\nTldr: I am in a toxic cycle where I am unable to experience happiness except when the men I am dating save me.\\n\",\"index\":3,\"finish_reason\":\"stop\"}],\"object\":\"text_completion\",\"id\":\"cmpl-9upy7sQ0QBDnrpHzGsoTTSyUEXIL8\",\"created\":\"1723333163\"} |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"21c0ab5f-6f79-48c7-a2cb-c32bdf6efbe2"},{"cell_type":"code","source":["from pyspark.sql.functions import posexplode, col, expr\n","# Explode and combine arrays into rows\n","df_exploded = completed_batch_df.select(\n","    posexplode(\"batchPrompt\").alias(\"pos\", \"Prompt\"),\"completions.choices\")\n","\n","display(df_exploded)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"43221bee-865b-400b-9b4f-87921a94d3e6"},{"cell_type":"code","source":["# Rename columns\n","df_final = df_exploded.select(\"Prompt\",expr(f\"choices[pos].text\").alias(\"selected_text\"))\n","display(df_final)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"d626462b-9797-40c9-8cf9-fc134ef2f2b6"},{"cell_type":"markdown","source":["### Using an automatic minibatcher\n","\n","If your data is in column format, you can transpose it to row format using SynapseML's `FixedMiniBatcherTransformer`."],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2dd7259b-173a-41ef-b98e-7b1dc0df875f","showTitle":false,"title":""}},"id":"690469a6-b8a2-4dc3-aa3e-dd22e8153d1d"},{"cell_type":"code","source":["display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"fd1ded2f-c9d8-4fb2-be5f-2e821f398b3f"},{"cell_type":"code","source":["from pyspark.sql.types import StringType\n","from synapse.ml.stages import FixedMiniBatchTransformer\n","from synapse.ml.core.spark import FluentAPI\n","\n","completed_autobatch_df = (\n","    df.coalesce(\n","        2\n","    )\n","    .mlTransform(FixedMiniBatchTransformer(batchSize=3))\n","    .withColumnRenamed(\"prompt\", \"batchPrompt\")\n","    .mlTransform(batch_completion)\n",")"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"04212778-8002-4e30-bf31-b7511c5776fd","showTitle":false,"title":""},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"20cf8352-cb6b-455d-bba3-3137258a5e4f"},{"cell_type":"code","source":["completed_autobatch_df_1 = (\n","     df.coalesce(\n","        2\n","    ))\n","\n","from pyspark.sql.functions  import spark_partition_id\n","completed_autobatch_df_1.withColumn(\"partitionId\", spark_partition_id()).groupBy(\"partitionId\").count().show()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"445abf42-3d7b-4b56-9dc5-a3e9b397bb5a"},{"cell_type":"code","source":["display(completed_autobatch_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"15c5cfc8-835c-4e60-8c51-e48d42bd8f1a"},{"cell_type":"code","source":["\n","from pyspark.sql.functions import posexplode, col, expr\n","# Explode and combine arrays into rows\n","df_exploded = completed_autobatch_df.select(\n","    posexplode(\"batchPrompt\").alias(\"pos\", \"Prompt\"),\"completions.choices\")\n","\n","display(df_exploded)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"d63518fe-26a2-4b2e-9c0f-dee825d075b1"},{"cell_type":"code","source":["# Rename columns\n","df_final = df_exploded.select(\"Prompt\",expr(f\"choices[pos].text\").alias(\"selected_text\"))\n","display(df_final)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"02d39fd7-7cc5-4f53-b04a-a78e4ea6b5c8"},{"cell_type":"markdown","source":["### Prompt engineering for translation\n","\n","The Azure OpenAI service can solve many different natural language tasks through [prompt engineering](https://docs.microsoft.com/en-us/azure/cognitive-services/openai/how-to/completions). Here, we show an example of prompting for language translation:"],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f1611cd5-1af9-458f-a1d5-b1f517194cc8","showTitle":false,"title":""}},"id":"c817582e-f335-4ed3-a7f0-ea05dd91d868"},{"cell_type":"code","source":["translate_df = spark.createDataFrame(\n","    [\n","        (\"Japanese: Ookina hako \\nEnglish: Big box \\nJapanese: Midori tako\\nEnglish:\",),\n","        (\n","            \"French: Quel heure et il au Montreal? \\nEnglish: What time is it in Montreal? \\nFrench: Ou est le poulet? \\nEnglish:\",\n","        ),\n","    ]\n",").toDF(\"prompt\")\n","\n"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0cee629b-240d-411f-a067-9f7b9ac6ce5d","showTitle":false,"title":""},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"1819ba05-72ba-4a06-a68f-fe851e69270a"},{"cell_type":"code","source":["display(translate_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"3723a4a8-a7f6-4441-adc4-4327fd95312e"},{"cell_type":"code","source":["display(completion.transform(translate_df))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f566452c-e867-4c32-a258-aa026b8d7e34"},{"cell_type":"markdown","source":["### Prompt for question answering\n","\n","Here, we prompt GPT-3 for general-knowledge question answering:"],"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"3a726683-8e19-4ebf-8244-bde82ec4fdbe","showTitle":false,"title":""}},"id":"7426683e-2e7d-468c-b1cd-43928946660d"},{"cell_type":"code","source":["qa_df = spark.createDataFrame(\n","    [\n","        (\n","            \"Q: Where is the Grand Canyon?\\nA: The Grand Canyon is in Arizona.\\n\\nQ: What is the weight of the Burj Khalifa in kilograms?\\nA:\",\n","        )\n","    ]\n",").toDF(\"prompt\")\n","\n","display(completion.transform(qa_df))"],"outputs":[],"execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"831abdac-4b6c-4b7d-b99a-43dcb75c4169","showTitle":false,"title":""},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"76db5987-b0a4-49f6-8c2b-1a99e12e92c3"}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"AI Services - OpenAI","notebookOrigID":2846029038781816,"widgets":{}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"state":{},"version":"0.1"},"save_output":true,"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"environment":{}}},"nbformat":4,"nbformat_minor":5}